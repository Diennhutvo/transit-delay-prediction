{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcadd704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\nhutd\\anaconda3\\lib\\site-packages (1.42.40)\n",
      "Requirement already satisfied: protobuf in c:\\users\\nhutd\\anaconda3\\lib\\site-packages (4.25.3)\n",
      "Requirement already satisfied: gtfs-realtime-bindings in c:\\users\\nhutd\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: botocore<1.43.0,>=1.42.40 in c:\\users\\nhutd\\anaconda3\\lib\\site-packages (from boto3) (1.42.40)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\nhutd\\anaconda3\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in c:\\users\\nhutd\\anaconda3\\lib\\site-packages (from boto3) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\nhutd\\anaconda3\\lib\\site-packages (from botocore<1.43.0,>=1.42.40->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\nhutd\\anaconda3\\lib\\site-packages (from botocore<1.43.0,>=1.42.40->boto3) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nhutd\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.40->boto3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install boto3 protobuf gtfs-realtime-bindings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9dc44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: gtfs_rt/trip_updates/year=2026/month=02/day=02/hour=14/ts=1770040810.pb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>delay_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14827490</td>\n",
       "      <td></td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14827491</td>\n",
       "      <td>6612</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>-34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>12040</td>\n",
       "      <td>19</td>\n",
       "      <td>-191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>10542</td>\n",
       "      <td>20</td>\n",
       "      <td>-199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>69</td>\n",
       "      <td>21</td>\n",
       "      <td>-212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "      <td>-207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>-214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>73</td>\n",
       "      <td>24</td>\n",
       "      <td>-256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>-220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>11881</td>\n",
       "      <td>26</td>\n",
       "      <td>-197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>12603</td>\n",
       "      <td>27</td>\n",
       "      <td>-202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>-187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>-156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14827593</td>\n",
       "      <td>6612</td>\n",
       "      <td>121</td>\n",
       "      <td>22</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14827593</td>\n",
       "      <td>6612</td>\n",
       "      <td>122</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14827593</td>\n",
       "      <td>6612</td>\n",
       "      <td>124</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14827593</td>\n",
       "      <td>6612</td>\n",
       "      <td>126</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14827593</td>\n",
       "      <td>6612</td>\n",
       "      <td>128</td>\n",
       "      <td>26</td>\n",
       "      <td>-12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14827593</td>\n",
       "      <td>6612</td>\n",
       "      <td>130</td>\n",
       "      <td>27</td>\n",
       "      <td>-37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14827593</td>\n",
       "      <td>6612</td>\n",
       "      <td>296</td>\n",
       "      <td>28</td>\n",
       "      <td>-45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14827593</td>\n",
       "      <td>6612</td>\n",
       "      <td>12671</td>\n",
       "      <td>29</td>\n",
       "      <td>-48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14827593</td>\n",
       "      <td>6612</td>\n",
       "      <td>299</td>\n",
       "      <td>30</td>\n",
       "      <td>-69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14827593</td>\n",
       "      <td>6612</td>\n",
       "      <td>300</td>\n",
       "      <td>31</td>\n",
       "      <td>-86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>162</td>\n",
       "      <td>14</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>163</td>\n",
       "      <td>15</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>165</td>\n",
       "      <td>16</td>\n",
       "      <td>-17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>166</td>\n",
       "      <td>17</td>\n",
       "      <td>-21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>167</td>\n",
       "      <td>18</td>\n",
       "      <td>-30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>169</td>\n",
       "      <td>19</td>\n",
       "      <td>-31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>10611</td>\n",
       "      <td>20</td>\n",
       "      <td>-48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>170</td>\n",
       "      <td>21</td>\n",
       "      <td>-59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>171</td>\n",
       "      <td>22</td>\n",
       "      <td>-68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>10816</td>\n",
       "      <td>23</td>\n",
       "      <td>-55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>174</td>\n",
       "      <td>24</td>\n",
       "      <td>-42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>176</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>177</td>\n",
       "      <td>26</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>178</td>\n",
       "      <td>27</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>179</td>\n",
       "      <td>28</td>\n",
       "      <td>-14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>181</td>\n",
       "      <td>29</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>182</td>\n",
       "      <td>30</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>184</td>\n",
       "      <td>31</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>3428</td>\n",
       "      <td>32</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>186</td>\n",
       "      <td>33</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>3429</td>\n",
       "      <td>34</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>188</td>\n",
       "      <td>35</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>14828107</td>\n",
       "      <td>6613</td>\n",
       "      <td>859</td>\n",
       "      <td>36</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>14828108</td>\n",
       "      <td>6613</td>\n",
       "      <td>184</td>\n",
       "      <td>31</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>14828108</td>\n",
       "      <td>6613</td>\n",
       "      <td>3428</td>\n",
       "      <td>32</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>14828108</td>\n",
       "      <td>6613</td>\n",
       "      <td>186</td>\n",
       "      <td>33</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>14828108</td>\n",
       "      <td>6613</td>\n",
       "      <td>3429</td>\n",
       "      <td>34</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     trip_id route_id stop_id  stop_sequence  delay_sec\n",
       "0   14827490               31             29       43.0\n",
       "1   14827491     6612      31             29      -34.0\n",
       "2   14827492     6612   12040             19     -191.0\n",
       "3   14827492     6612   10542             20     -199.0\n",
       "4   14827492     6612      69             21     -212.0\n",
       "5   14827492     6612      70             22     -207.0\n",
       "6   14827492     6612      72             23     -214.0\n",
       "7   14827492     6612      73             24     -256.0\n",
       "8   14827492     6612      75             25     -220.0\n",
       "9   14827492     6612   11881             26     -197.0\n",
       "10  14827492     6612   12603             27     -202.0\n",
       "11  14827492     6612      30             28     -187.0\n",
       "12  14827492     6612      31             29     -156.0\n",
       "13  14827593     6612     121             22       27.0\n",
       "14  14827593     6612     122             23        NaN\n",
       "15  14827593     6612     124             24        NaN\n",
       "16  14827593     6612     126             25        NaN\n",
       "17  14827593     6612     128             26      -12.0\n",
       "18  14827593     6612     130             27      -37.0\n",
       "19  14827593     6612     296             28      -45.0\n",
       "20  14827593     6612   12671             29      -48.0\n",
       "21  14827593     6612     299             30      -69.0\n",
       "22  14827593     6612     300             31      -86.0\n",
       "23  14828107     6613     162             14       10.0\n",
       "24  14828107     6613     163             15       -6.0\n",
       "25  14828107     6613     165             16      -17.0\n",
       "26  14828107     6613     166             17      -21.0\n",
       "27  14828107     6613     167             18      -30.0\n",
       "28  14828107     6613     169             19      -31.0\n",
       "29  14828107     6613   10611             20      -48.0\n",
       "30  14828107     6613     170             21      -59.0\n",
       "31  14828107     6613     171             22      -68.0\n",
       "32  14828107     6613   10816             23      -55.0\n",
       "33  14828107     6613     174             24      -42.0\n",
       "34  14828107     6613     176             25        0.0\n",
       "35  14828107     6613     177             26       11.0\n",
       "36  14828107     6613     178             27       -1.0\n",
       "37  14828107     6613     179             28      -14.0\n",
       "38  14828107     6613     181             29       10.0\n",
       "39  14828107     6613     182             30       -3.0\n",
       "40  14828107     6613     184             31       -1.0\n",
       "41  14828107     6613    3428             32       32.0\n",
       "42  14828107     6613     186             33       19.0\n",
       "43  14828107     6613    3429             34       22.0\n",
       "44  14828107     6613     188             35       30.0\n",
       "45  14828107     6613     859             36       50.0\n",
       "46  14828108     6613     184             31      128.0\n",
       "47  14828108     6613    3428             32      183.0\n",
       "48  14828108     6613     186             33      180.0\n",
       "49  14828108     6613    3429             34      180.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from google.transit import gtfs_realtime_pb2\n",
    "\n",
    "bucket = \"bus-delay-forecast\"\n",
    "prefix = \"gtfs_rt/trip_updates/year=2026/month=02/day=02/hour=14/\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "resp = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "keys = [o[\"Key\"] for o in resp.get(\"Contents\", []) if o[\"Key\"].endswith(\".pb\")]\n",
    "keys.sort()\n",
    "\n",
    "print(\"Using:\", keys[0])\n",
    "\n",
    "pb = s3.get_object(Bucket=bucket, Key=keys[0])[\"Body\"].read()\n",
    "\n",
    "feed = gtfs_realtime_pb2.FeedMessage()\n",
    "feed.ParseFromString(pb)\n",
    "\n",
    "rows = []\n",
    "for ent in feed.entity:\n",
    "    if not ent.HasField(\"trip_update\"):\n",
    "        continue\n",
    "    tu = ent.trip_update\n",
    "    for stu in tu.stop_time_update:\n",
    "        rows.append({\n",
    "            \"trip_id\": tu.trip.trip_id,\n",
    "            \"route_id\": tu.trip.route_id,\n",
    "            \"stop_id\": stu.stop_id,\n",
    "            \"stop_sequence\": stu.stop_sequence if stu.HasField(\"stop_sequence\") else None,\n",
    "            \"delay_sec\": stu.arrival.delay if stu.HasField(\"arrival\") else None\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed552ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 60\n",
      "First 5 keys:\n",
      "gtfs_rt/trip_updates/year=2026/month=02/day=02/hour=14/ts=1770040810.pb\n",
      "gtfs_rt/trip_updates/year=2026/month=02/day=02/hour=14/ts=1770040870.pb\n",
      "gtfs_rt/trip_updates/year=2026/month=02/day=02/hour=14/ts=1770040930.pb\n",
      "gtfs_rt/trip_updates/year=2026/month=02/day=02/hour=14/ts=1770040990.pb\n",
      "gtfs_rt/trip_updates/year=2026/month=02/day=02/hour=14/ts=1770041050.pb\n",
      "\n",
      "Using key: gtfs_rt/trip_updates/year=2026/month=02/day=02/hour=14/ts=1770040810.pb\n",
      "Downloaded bytes: 661670\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "bucket = \"bus-delay-forecast\"\n",
    "prefix = \"gtfs_rt/trip_updates/year=2026/month=02/day=02/hour=14/\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "resp = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "keys = sorted([o[\"Key\"] for o in resp.get(\"Contents\", []) if o[\"Key\"].endswith(\".pb\")])\n",
    "\n",
    "print(\"Found:\", len(keys))\n",
    "print(\"First 5 keys:\")\n",
    "for k in keys[:5]:\n",
    "    print(k)\n",
    "\n",
    "# pick one that definitely exists\n",
    "key = keys[0]\n",
    "print(\"\\nUsing key:\", key)\n",
    "\n",
    "pb_bytes = s3.get_object(Bucket=bucket, Key=key)[\"Body\"].read()\n",
    "print(\"Downloaded bytes:\", len(pb_bytes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f00e6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 60\n",
      "Example key: gtfs_rt/trip_updates/year=2026/month=02/day=02/hour=14/ts=1770040810.pb\n",
      "Bytes: 661670\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "bucket = \"bus-delay-forecast\"\n",
    "prefix = \"gtfs_rt/trip_updates/year=2026/month=02/day=02/hour=14/\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "resp = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "keys = sorted(o[\"Key\"] for o in resp[\"Contents\"] if o[\"Key\"].endswith(\".pb\"))\n",
    "\n",
    "print(\"Found:\", len(keys))\n",
    "print(\"Example key:\", keys[0])\n",
    "\n",
    "pb_bytes = s3.get_object(Bucket=bucket, Key=keys[0])[\"Body\"].read()\n",
    "print(\"Bytes:\", len(pb_bytes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce75e00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip {\n",
      "  trip_id: \"14827490\"\n",
      "  start_date: \"20260202\"\n",
      "  schedule_relationship: SCHEDULED\n",
      "  direction_id: 0\n",
      "}\n",
      "stop_time_update {\n",
      "  stop_sequence: 29\n",
      "  arrival {\n",
      "    delay: 43\n",
      "    time: 1770039216\n",
      "  }\n",
      "  departure {\n",
      "    delay: 43\n",
      "    time: 1770039216\n",
      "  }\n",
      "  stop_id: \"31\"\n",
      "  schedule_relationship: SCHEDULED\n",
      "}\n",
      "vehicle {\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.transit import gtfs_realtime_pb2\n",
    "\n",
    "feed = gtfs_realtime_pb2.FeedMessage()\n",
    "feed.ParseFromString(pb_bytes)\n",
    "\n",
    "# Print the first full TripUpdate\n",
    "for ent in feed.entity:\n",
    "    if ent.HasField(\"trip_update\"):\n",
    "        print(ent.trip_update)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39c7a983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtfs_realtime_version: \"2.0\"\n",
      "incrementality: FULL_DATASET\n",
      "timestamp: 1770040801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(feed.header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585c25b9",
   "metadata": {},
   "source": [
    "# Testing with monday - 8 am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b2ceab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PB files found: 60 Example: gtfs_rt/trip_updates/year=2026/month=02/day=02/hour=14/ts=1770040810.pb\n",
      "(142906, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feed_timestamp</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>delay_sec</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1770040801</td>\n",
       "      <td>14827490</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2026-02-02 14:00:01+00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1770040801</td>\n",
       "      <td>14827491</td>\n",
       "      <td>6612</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>2026-02-02 14:00:01+00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1770040801</td>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>12040</td>\n",
       "      <td>19</td>\n",
       "      <td>-191.0</td>\n",
       "      <td>2026-02-02 14:00:01+00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1770040801</td>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>10542</td>\n",
       "      <td>20</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>2026-02-02 14:00:01+00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1770040801</td>\n",
       "      <td>14827492</td>\n",
       "      <td>6612</td>\n",
       "      <td>69</td>\n",
       "      <td>21</td>\n",
       "      <td>-212.0</td>\n",
       "      <td>2026-02-02 14:00:01+00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feed_timestamp   trip_id route_id stop_id  stop_sequence  delay_sec  \\\n",
       "0      1770040801  14827490     None      31             29       43.0   \n",
       "1      1770040801  14827491     6612      31             29      -34.0   \n",
       "2      1770040801  14827492     6612   12040             19     -191.0   \n",
       "3      1770040801  14827492     6612   10542             20     -199.0   \n",
       "4      1770040801  14827492     6612      69             21     -212.0   \n",
       "\n",
       "                  timestamp  hour  day_of_week  \n",
       "0 2026-02-02 14:00:01+00:00    14            0  \n",
       "1 2026-02-02 14:00:01+00:00    14            0  \n",
       "2 2026-02-02 14:00:01+00:00    14            0  \n",
       "3 2026-02-02 14:00:01+00:00    14            0  \n",
       "4 2026-02-02 14:00:01+00:00    14            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with 14 hours\n",
    "import re, io\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from google.transit import gtfs_realtime_pb2\n",
    "\n",
    "bucket = \"bus-delay-forecast\"\n",
    "in_prefix = \"gtfs_rt/trip_updates/year=2026/month=02/day=02/hour=14/\"\n",
    "out_key = \"processed/gtfs_rt/trip_updates_parquet/year=2026/month=02/day=02/hour=14/part-000.parquet\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "TS_RE = re.compile(r\"ts=(\\d+)\\.pb$\")\n",
    "\n",
    "def parse_tripupdates(pb_bytes: bytes, default_feed_ts=None):\n",
    "    feed = gtfs_realtime_pb2.FeedMessage()\n",
    "    feed.ParseFromString(pb_bytes)\n",
    "    feed_ts = feed.header.timestamp if feed.header and feed.header.timestamp else default_feed_ts\n",
    "\n",
    "    rows = []\n",
    "    for ent in feed.entity:\n",
    "        if not ent.HasField(\"trip_update\"):\n",
    "            continue\n",
    "        tu = ent.trip_update\n",
    "        trip_id = tu.trip.trip_id if tu.trip.trip_id else None\n",
    "        route_id = tu.trip.route_id if tu.trip.route_id else None\n",
    "\n",
    "        for stu in tu.stop_time_update:\n",
    "            delay_sec = None\n",
    "            if stu.HasField(\"arrival\") and stu.arrival.HasField(\"delay\"):\n",
    "                delay_sec = stu.arrival.delay\n",
    "            elif stu.HasField(\"departure\") and stu.departure.HasField(\"delay\"):\n",
    "                delay_sec = stu.departure.delay\n",
    "\n",
    "            rows.append({\n",
    "                \"feed_timestamp\": feed_ts,\n",
    "                \"trip_id\": trip_id,\n",
    "                \"route_id\": route_id,\n",
    "                \"stop_id\": stu.stop_id if stu.stop_id else None,\n",
    "                \"stop_sequence\": stu.stop_sequence if stu.HasField(\"stop_sequence\") else None,\n",
    "                \"delay_sec\": delay_sec,\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "# 1) list pb files in hour=14\n",
    "resp = s3.list_objects_v2(Bucket=bucket, Prefix=in_prefix)\n",
    "keys = sorted([o[\"Key\"] for o in resp.get(\"Contents\", []) if o[\"Key\"].endswith(\".pb\")])\n",
    "print(\"PB files found:\", len(keys), \"Example:\", keys[0])\n",
    "\n",
    "# 2) parse a manageable number first (e.g., first 10 files)\n",
    "all_rows = []\n",
    "for k in keys[:10]:\n",
    "    m = TS_RE.search(k)\n",
    "    ts_from_name = int(m.group(1)) if m else None\n",
    "    pb = s3.get_object(Bucket=bucket, Key=k)[\"Body\"].read()\n",
    "    all_rows.extend(parse_tripupdates(pb, default_feed_ts=ts_from_name))\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "\n",
    "# 3) add handy time features\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"feed_timestamp\"], unit=\"s\", utc=True)\n",
    "df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "df[\"day_of_week\"] = df[\"timestamp\"].dt.dayofweek\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "035211c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/year=2026/month=02/day=02/hour=14/part-000.parquet\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import boto3\n",
    "\n",
    "bucket = \"bus-delay-forecast\"\n",
    "out_key = (\n",
    "    \"processed/gtfs_rt/trip_updates_parquet/\"\n",
    "    \"year=2026/month=02/day=02/hour=14/part-000.parquet\"\n",
    ")\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "buf = io.BytesIO()\n",
    "df.to_parquet(buf, index=False)\n",
    "buf.seek(0)\n",
    "\n",
    "s3.put_object(\n",
    "    Bucket=bucket,\n",
    "    Key=out_key,\n",
    "    Body=buf.getvalue()\n",
    ")\n",
    "\n",
    "print(\"Wrote:\", f\"s3://{bucket}/{out_key}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8467a46",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ClientArgsCreator.compute_endpoint_resolver_builtin_defaults() missing 2 required positional arguments: 'credentials' and 'account_id_endpoint_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df_public \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/year=2026/month=02/day=02/hour=14/part-000.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manon\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m df_public\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    668\u001b[0m     path,\n\u001b[0;32m    669\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    670\u001b[0m     filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    671\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    672\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    673\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    674\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    676\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:274\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    268\u001b[0m     path,\n\u001b[0;32m    269\u001b[0m     filesystem,\n\u001b[0;32m    270\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    271\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    272\u001b[0m )\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    275\u001b[0m         path_or_handle,\n\u001b[0;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    277\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    278\u001b[0m         filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    280\u001b[0m     )\n\u001b[0;32m    281\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1762\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[0;32m   1756\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1757\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated as of pyarrow 15.0.0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1758\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand will be removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1759\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m   1761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1762\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m ParquetDataset(\n\u001b[0;32m   1763\u001b[0m         source,\n\u001b[0;32m   1764\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   1765\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m   1766\u001b[0m         partitioning\u001b[38;5;241m=\u001b[39mpartitioning,\n\u001b[0;32m   1767\u001b[0m         memory_map\u001b[38;5;241m=\u001b[39mmemory_map,\n\u001b[0;32m   1768\u001b[0m         read_dictionary\u001b[38;5;241m=\u001b[39mread_dictionary,\n\u001b[0;32m   1769\u001b[0m         buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size,\n\u001b[0;32m   1770\u001b[0m         filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m   1771\u001b[0m         ignore_prefixes\u001b[38;5;241m=\u001b[39mignore_prefixes,\n\u001b[0;32m   1772\u001b[0m         pre_buffer\u001b[38;5;241m=\u001b[39mpre_buffer,\n\u001b[0;32m   1773\u001b[0m         coerce_int96_timestamp_unit\u001b[38;5;241m=\u001b[39mcoerce_int96_timestamp_unit,\n\u001b[0;32m   1774\u001b[0m         thrift_string_size_limit\u001b[38;5;241m=\u001b[39mthrift_string_size_limit,\n\u001b[0;32m   1775\u001b[0m         thrift_container_size_limit\u001b[38;5;241m=\u001b[39mthrift_container_size_limit,\n\u001b[0;32m   1776\u001b[0m         page_checksum_verification\u001b[38;5;241m=\u001b[39mpage_checksum_verification,\n\u001b[0;32m   1777\u001b[0m     )\n\u001b[0;32m   1778\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m     \u001b[38;5;66;03m# module is not available\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1315\u001b[0m, in \u001b[0;36mParquetDataset.__init__\u001b[1;34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, use_legacy_dataset)\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m         filesystem \u001b[38;5;241m=\u001b[39m LocalFileSystem(use_mmap\u001b[38;5;241m=\u001b[39mmemory_map)\n\u001b[1;32m-> 1315\u001b[0m finfo \u001b[38;5;241m=\u001b[39m filesystem\u001b[38;5;241m.\u001b[39mget_file_info(path_or_paths)\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m finfo\u001b[38;5;241m.\u001b[39mis_file:\n\u001b[0;32m   1317\u001b[0m     single_file \u001b[38;5;241m=\u001b[39m path_or_paths\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\pyarrow\\_fs.pyx:584\u001b[0m, in \u001b[0;36mpyarrow._fs.FileSystem.get_file_info\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\pyarrow\\error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\pyarrow\\error.pxi:88\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\pyarrow\\_fs.pyx:1504\u001b[0m, in \u001b[0;36mpyarrow._fs._cb_get_file_info\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\pyarrow\\fs.py:322\u001b[0m, in \u001b[0;36mFSSpecHandler.get_file_info\u001b[1;34m(self, paths)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths:\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 322\u001b[0m         info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39minfo(path)\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m         infos\u001b[38;5;241m.\u001b[39mappend(FileInfo(path, FileType\u001b[38;5;241m.\u001b[39mNotFound))\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\fsspec\\asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\fsspec\\asyn.py:103\u001b[0m, in \u001b[0;36msync\u001b[1;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\fsspec\\asyn.py:56\u001b[0m, in \u001b[0;36m_runner\u001b[1;34m(event, coro, result, timeout)\u001b[0m\n\u001b[0;32m     54\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m     58\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\s3fs\\core.py:1374\u001b[0m, in \u001b[0;36mS3FileSystem._info\u001b[1;34m(self, path, bucket, key, refresh, version_id)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key:\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_s3(\n\u001b[0;32m   1375\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_object\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1376\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[0;32m   1377\u001b[0m             Bucket\u001b[38;5;241m=\u001b[39mbucket,\n\u001b[0;32m   1378\u001b[0m             Key\u001b[38;5;241m=\u001b[39mkey,\n\u001b[0;32m   1379\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mversion_id_kw(version_id),\n\u001b[0;32m   1380\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreq_kw,\n\u001b[0;32m   1381\u001b[0m         )\n\u001b[0;32m   1382\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m   1383\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETag\u001b[39m\u001b[38;5;124m\"\u001b[39m: out\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1384\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLastModified\u001b[39m\u001b[38;5;124m\"\u001b[39m: out\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLastModified\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContentType\u001b[39m\u001b[38;5;124m\"\u001b[39m: out\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContentType\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1391\u001b[0m         }\n\u001b[0;32m   1392\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\s3fs\\core.py:358\u001b[0m, in \u001b[0;36mS3FileSystem._call_s3\u001b[1;34m(self, method, *akwarglist, **kwargs)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_s3\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, \u001b[38;5;241m*\u001b[39makwarglist, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_session()\n\u001b[0;32m    359\u001b[0m     s3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_s3(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBucket\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    360\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(s3, method)\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\s3fs\\core.py:544\u001b[0m, in \u001b[0;36mS3FileSystem.set_session\u001b[1;34m(self, refresh, kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    541\u001b[0m     s3creator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mcreate_client(\n\u001b[0;32m    542\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m=\u001b[39mconf, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_kwargs\n\u001b[0;32m    543\u001b[0m     )\n\u001b[1;32m--> 544\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_s3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m s3creator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__aenter__\u001b[39m()\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_s3creator \u001b[38;5;241m=\u001b[39m s3creator\n\u001b[0;32m    547\u001b[0m \u001b[38;5;66;03m# the following actually closes the aiohttp connection; use of privates\u001b[39;00m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;66;03m# might break in the future, would cause exception at gc time\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\aiobotocore\\session.py:25\u001b[0m, in \u001b[0;36mClientCreatorContext.__aenter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AioBaseClient:\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__aenter__\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\aiobotocore\\session.py:215\u001b[0m, in \u001b[0;36mAioSession._create_client\u001b[1;34m(self, service_name, region_name, api_version, use_ssl, verify, endpoint_url, aws_access_key_id, aws_secret_access_key, aws_session_token, config)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_configured_endpoint_provider(\n\u001b[0;32m    200\u001b[0m     client_name\u001b[38;5;241m=\u001b[39mservice_name,\n\u001b[0;32m    201\u001b[0m     config_store\u001b[38;5;241m=\u001b[39mconfig_store,\n\u001b[0;32m    202\u001b[0m )\n\u001b[0;32m    203\u001b[0m client_creator \u001b[38;5;241m=\u001b[39m AioClientCreator(\n\u001b[0;32m    204\u001b[0m     loader,\n\u001b[0;32m    205\u001b[0m     endpoint_resolver,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    213\u001b[0m     user_agent_creator\u001b[38;5;241m=\u001b[39muser_agent_creator,\n\u001b[0;32m    214\u001b[0m )\n\u001b[1;32m--> 215\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m client_creator\u001b[38;5;241m.\u001b[39mcreate_client(\n\u001b[0;32m    216\u001b[0m     service_name\u001b[38;5;241m=\u001b[39mservice_name,\n\u001b[0;32m    217\u001b[0m     region_name\u001b[38;5;241m=\u001b[39mregion_name,\n\u001b[0;32m    218\u001b[0m     is_secure\u001b[38;5;241m=\u001b[39muse_ssl,\n\u001b[0;32m    219\u001b[0m     endpoint_url\u001b[38;5;241m=\u001b[39mendpoint_url,\n\u001b[0;32m    220\u001b[0m     verify\u001b[38;5;241m=\u001b[39mverify,\n\u001b[0;32m    221\u001b[0m     credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[0;32m    222\u001b[0m     scoped_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_scoped_config(),\n\u001b[0;32m    223\u001b[0m     client_config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    224\u001b[0m     api_version\u001b[38;5;241m=\u001b[39mapi_version,\n\u001b[0;32m    225\u001b[0m     auth_token\u001b[38;5;241m=\u001b[39mauth_token,\n\u001b[0;32m    226\u001b[0m )\n\u001b[0;32m    227\u001b[0m monitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_internal_component(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonitor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m monitor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\aiobotocore\\client.py:77\u001b[0m, in \u001b[0;36mAioClientCreator.create_client\u001b[1;34m(self, service_name, region_name, is_secure, endpoint_url, verify, credentials, scoped_config, api_version, client_config, auth_token)\u001b[0m\n\u001b[0;32m     64\u001b[0m region_name, client_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_fips_region(\n\u001b[0;32m     65\u001b[0m     region_name, client_config\n\u001b[0;32m     66\u001b[0m )\n\u001b[0;32m     67\u001b[0m endpoint_bridge \u001b[38;5;241m=\u001b[39m ClientEndpointBridge(\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_endpoint_resolver,\n\u001b[0;32m     69\u001b[0m     scoped_config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m     ),\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m client_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_client_args(\n\u001b[0;32m     78\u001b[0m     service_model,\n\u001b[0;32m     79\u001b[0m     region_name,\n\u001b[0;32m     80\u001b[0m     is_secure,\n\u001b[0;32m     81\u001b[0m     endpoint_url,\n\u001b[0;32m     82\u001b[0m     verify,\n\u001b[0;32m     83\u001b[0m     credentials,\n\u001b[0;32m     84\u001b[0m     scoped_config,\n\u001b[0;32m     85\u001b[0m     client_config,\n\u001b[0;32m     86\u001b[0m     endpoint_bridge,\n\u001b[0;32m     87\u001b[0m     auth_token,\n\u001b[0;32m     88\u001b[0m     endpoints_ruleset_data,\n\u001b[0;32m     89\u001b[0m     partition_data,\n\u001b[0;32m     90\u001b[0m )\n\u001b[0;32m     91\u001b[0m service_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_args)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_retries(service_client)\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\aiobotocore\\client.py:283\u001b[0m, in \u001b[0;36mAioClientCreator._get_client_args\u001b[1;34m(self, service_model, region_name, is_secure, endpoint_url, verify, credentials, scoped_config, client_config, endpoint_bridge, auth_token, endpoints_ruleset_data, partition_data)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_client_args\u001b[39m(\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m     service_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# This is a near copy of ClientCreator. What's replaced\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# is ClientArgsCreator->AioClientArgsCreator\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     args_creator \u001b[38;5;241m=\u001b[39m AioClientArgsCreator(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_emitter,\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_agent,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m         user_agent_creator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_agent_creator,\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args_creator\u001b[38;5;241m.\u001b[39mget_client_args(\n\u001b[0;32m    284\u001b[0m         service_model,\n\u001b[0;32m    285\u001b[0m         region_name,\n\u001b[0;32m    286\u001b[0m         is_secure,\n\u001b[0;32m    287\u001b[0m         endpoint_url,\n\u001b[0;32m    288\u001b[0m         verify,\n\u001b[0;32m    289\u001b[0m         credentials,\n\u001b[0;32m    290\u001b[0m         scoped_config,\n\u001b[0;32m    291\u001b[0m         client_config,\n\u001b[0;32m    292\u001b[0m         endpoint_bridge,\n\u001b[0;32m    293\u001b[0m         auth_token,\n\u001b[0;32m    294\u001b[0m         endpoints_ruleset_data,\n\u001b[0;32m    295\u001b[0m         partition_data,\n\u001b[0;32m    296\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\aiobotocore\\args.py:99\u001b[0m, in \u001b[0;36mAioClientArgsCreator.get_client_args\u001b[1;34m(self, service_model, region_name, is_secure, endpoint_url, verify, credentials, scoped_config, client_config, endpoint_bridge, auth_token, endpoints_ruleset_data, partition_data)\u001b[0m\n\u001b[0;32m     94\u001b[0m serializer \u001b[38;5;241m=\u001b[39m botocore\u001b[38;5;241m.\u001b[39mserialize\u001b[38;5;241m.\u001b[39mcreate_serializer(\n\u001b[0;32m     95\u001b[0m     protocol, parameter_validation\n\u001b[0;32m     96\u001b[0m )\n\u001b[0;32m     97\u001b[0m response_parser \u001b[38;5;241m=\u001b[39m botocore\u001b[38;5;241m.\u001b[39mparsers\u001b[38;5;241m.\u001b[39mcreate_parser(protocol)\n\u001b[1;32m---> 99\u001b[0m ruleset_resolver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_endpoint_resolver(\n\u001b[0;32m    100\u001b[0m     endpoints_ruleset_data,\n\u001b[0;32m    101\u001b[0m     partition_data,\n\u001b[0;32m    102\u001b[0m     client_config,\n\u001b[0;32m    103\u001b[0m     service_model,\n\u001b[0;32m    104\u001b[0m     endpoint_region_name,\n\u001b[0;32m    105\u001b[0m     region_name,\n\u001b[0;32m    106\u001b[0m     configured_endpoint_url,\n\u001b[0;32m    107\u001b[0m     endpoint,\n\u001b[0;32m    108\u001b[0m     is_secure,\n\u001b[0;32m    109\u001b[0m     endpoint_bridge,\n\u001b[0;32m    110\u001b[0m     event_emitter,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Copy the session's user agent factory and adds client configuration.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m client_ua_creator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session_ua_creator\u001b[38;5;241m.\u001b[39mwith_client_config(\n\u001b[0;32m    115\u001b[0m     new_config\n\u001b[0;32m    116\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\nhutd\\anaconda3\\Lib\\site-packages\\aiobotocore\\args.py:165\u001b[0m, in \u001b[0;36mAioClientArgsCreator._build_endpoint_resolver\u001b[1;34m(self, endpoints_ruleset_data, partition_data, client_config, service_model, endpoint_region_name, region_name, endpoint_url, endpoint, is_secure, endpoint_bridge, event_emitter)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     eprv2_region_name \u001b[38;5;241m=\u001b[39m region_name\n\u001b[1;32m--> 165\u001b[0m resolver_builtins \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_endpoint_resolver_builtin_defaults(\n\u001b[0;32m    166\u001b[0m     region_name\u001b[38;5;241m=\u001b[39meprv2_region_name,\n\u001b[0;32m    167\u001b[0m     service_name\u001b[38;5;241m=\u001b[39mservice_name_raw,\n\u001b[0;32m    168\u001b[0m     s3_config\u001b[38;5;241m=\u001b[39ms3_config_raw,\n\u001b[0;32m    169\u001b[0m     endpoint_bridge\u001b[38;5;241m=\u001b[39mendpoint_bridge,\n\u001b[0;32m    170\u001b[0m     client_endpoint_url\u001b[38;5;241m=\u001b[39mendpoint_url,\n\u001b[0;32m    171\u001b[0m     legacy_endpoint_url\u001b[38;5;241m=\u001b[39mendpoint\u001b[38;5;241m.\u001b[39mhost,\n\u001b[0;32m    172\u001b[0m )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Client context params for s3 conflict with the available settings\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# in the `s3` parameter on the `Config` object. If the same parameter\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# is set in both places, the value in the `s3` parameter takes priority.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: ClientArgsCreator.compute_endpoint_resolver_builtin_defaults() missing 2 required positional arguments: 'credentials' and 'account_id_endpoint_mode'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_public = pd.read_parquet(\n",
    "    \"s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/year=2026/month=02/day=02/hour=14/part-000.parquet\",\n",
    "    storage_options={\"anon\": True},\n",
    ")\n",
    "\n",
    "df_public.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d39a72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-02  2026-02-06\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "# Yesterday (Friday)\n",
    "end_date = date.today() - timedelta(days=1)\n",
    "\n",
    "# Monday of that week\n",
    "start_date = end_date - timedelta(days=end_date.weekday())\n",
    "\n",
    "print(start_date, \"\", end_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f910b7d1",
   "metadata": {},
   "source": [
    "# Starting to build the entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b9c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "from google.transit import gtfs_realtime_pb2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8afc736",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "bucket = \"bus-delay-forecast\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d256926",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_RE = re.compile(r\"ts=(\\d+)\\.pb$\")\n",
    "\n",
    "def parse_tripupdates(pb_bytes, default_feed_ts=None):\n",
    "    feed = gtfs_realtime_pb2.FeedMessage()\n",
    "    feed.ParseFromString(pb_bytes)\n",
    "\n",
    "    feed_ts = (\n",
    "        feed.header.timestamp\n",
    "        if feed.header and feed.header.timestamp\n",
    "        else default_feed_ts\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    for ent in feed.entity:\n",
    "        if not ent.HasField(\"trip_update\"):\n",
    "            continue\n",
    "\n",
    "        tu = ent.trip_update\n",
    "        trip = tu.trip\n",
    "\n",
    "        for stu in tu.stop_time_update:\n",
    "            delay_sec = None\n",
    "            if stu.HasField(\"arrival\") and stu.arrival.HasField(\"delay\"):\n",
    "                delay_sec = stu.arrival.delay\n",
    "            elif stu.HasField(\"departure\") and stu.departure.HasField(\"delay\"):\n",
    "                delay_sec = stu.departure.delay\n",
    "\n",
    "            rows.append({\n",
    "                \"feed_timestamp\": feed_ts,\n",
    "                \"trip_id\": trip.trip_id or None,\n",
    "                \"route_id\": trip.route_id or None,\n",
    "                \"stop_id\": stu.stop_id or None,\n",
    "                \"stop_sequence\": stu.stop_sequence if stu.HasField(\"stop_sequence\") else None,\n",
    "                \"delay_sec\": delay_sec,\n",
    "            })\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fb182ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test window: 2026-02-02  2026-02-07\n",
      "\n",
      " 2026-02-02 | hours found: 6 | prefix: gtfs_rt/trip_updates/year=2026/month=02/day=02/\n",
      "   hour=07 files=1 (parallel workers=24)\n",
      "    ...parsed 1/1 files\n",
      "   WROTE hour=07 rows=5,869 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=02/hour=07/part-000.parquet (1.2s)\n",
      "   hour=13 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=13 rows=519,919 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=02/hour=13/part-000.parquet (3.3s)\n",
      "   hour=14 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=14 rows=1,047,331 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=02/hour=14/part-000.parquet (5.0s)\n",
      "   hour=15 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=15 rows=1,091,451 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=02/hour=15/part-000.parquet (4.8s)\n",
      "   hour=16 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=16 rows=1,073,740 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=02/hour=16/part-000.parquet (4.8s)\n",
      "   hour=19 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=19 rows=837,889 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=02/hour=19/part-000.parquet (4.0s)\n",
      "\n",
      " 2026-02-03 | hours found: 9 | prefix: gtfs_rt/trip_updates/year=2026/month=02/day=03/\n",
      "   hour=00 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=00 rows=1,298,336 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=03/hour=00/part-000.parquet (4.8s)\n",
      "   hour=01 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=01 rows=1,280,604 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=03/hour=01/part-000.parquet (5.6s)\n",
      "   hour=02 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=02 rows=1,049,690 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=03/hour=02/part-000.parquet (4.9s)\n",
      "   hour=03 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=03 rows=785,972 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=03/hour=03/part-000.parquet (3.8s)\n",
      "   hour=13 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=13 rows=521,735 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=03/hour=13/part-000.parquet (3.3s)\n",
      "   hour=14 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=14 rows=1,085,792 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=03/hour=14/part-000.parquet (4.9s)\n",
      "   hour=15 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=15 rows=1,083,711 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=03/hour=15/part-000.parquet (5.8s)\n",
      "   hour=16 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=16 rows=1,075,217 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=03/hour=16/part-000.parquet (5.3s)\n",
      "   hour=19 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=19 rows=832,597 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=03/hour=19/part-000.parquet (4.0s)\n",
      "\n",
      " 2026-02-04 | hours found: 9 | prefix: gtfs_rt/trip_updates/year=2026/month=02/day=04/\n",
      "   hour=00 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=00 rows=1,317,884 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=04/hour=00/part-000.parquet (6.5s)\n",
      "   hour=01 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=01 rows=1,279,734 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=04/hour=01/part-000.parquet (6.6s)\n",
      "   hour=02 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=02 rows=1,058,975 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=04/hour=02/part-000.parquet (5.9s)\n",
      "   hour=03 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=03 rows=782,485 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=04/hour=03/part-000.parquet (4.8s)\n",
      "   hour=13 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=13 rows=531,721 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=04/hour=13/part-000.parquet (3.0s)\n",
      "   hour=14 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=14 rows=1,071,212 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=04/hour=14/part-000.parquet (5.0s)\n",
      "   hour=15 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=15 rows=1,101,859 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=04/hour=15/part-000.parquet (4.9s)\n",
      "   hour=16 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=16 rows=1,042,508 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=04/hour=16/part-000.parquet (5.4s)\n",
      "   hour=19 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=19 rows=835,704 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=04/hour=19/part-000.parquet (4.0s)\n",
      "\n",
      " 2026-02-05 | hours found: 9 | prefix: gtfs_rt/trip_updates/year=2026/month=02/day=05/\n",
      "   hour=00 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=00 rows=1,352,586 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=05/hour=00/part-000.parquet (7.1s)\n",
      "   hour=01 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=01 rows=1,330,678 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=05/hour=01/part-000.parquet (5.7s)\n",
      "   hour=02 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=02 rows=1,113,540 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=05/hour=02/part-000.parquet (5.5s)\n",
      "   hour=03 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=03 rows=853,678 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=05/hour=03/part-000.parquet (4.3s)\n",
      "   hour=13 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=13 rows=507,752 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=05/hour=13/part-000.parquet (3.0s)\n",
      "   hour=14 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=14 rows=1,056,158 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=05/hour=14/part-000.parquet (5.1s)\n",
      "   hour=15 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=15 rows=1,158,452 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=05/hour=15/part-000.parquet (5.6s)\n",
      "   hour=16 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=16 rows=1,159,753 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=05/hour=16/part-000.parquet (5.2s)\n",
      "   hour=19 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=19 rows=863,084 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=05/hour=19/part-000.parquet (4.3s)\n",
      "\n",
      " 2026-02-06 | hours found: 9 | prefix: gtfs_rt/trip_updates/year=2026/month=02/day=06/\n",
      "   hour=00 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=00 rows=1,340,790 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=06/hour=00/part-000.parquet (10.3s)\n",
      "   hour=01 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=01 rows=1,304,801 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=06/hour=01/part-000.parquet (6.4s)\n",
      "   hour=02 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=02 rows=1,104,464 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=06/hour=02/part-000.parquet (5.4s)\n",
      "   hour=03 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=03 rows=825,221 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=06/hour=03/part-000.parquet (4.2s)\n",
      "   hour=13 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=13 rows=509,893 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=06/hour=13/part-000.parquet (3.0s)\n",
      "   hour=14 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=14 rows=1,064,295 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=06/hour=14/part-000.parquet (5.3s)\n",
      "   hour=15 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=15 rows=1,148,405 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=06/hour=15/part-000.parquet (5.8s)\n",
      "   hour=16 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=16 rows=1,151,931 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=06/hour=16/part-000.parquet (7.8s)\n",
      "   hour=19 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=19 rows=860,410 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=06/hour=19/part-000.parquet (4.6s)\n",
      "\n",
      " 2026-02-07 | hours found: 9 | prefix: gtfs_rt/trip_updates/year=2026/month=02/day=07/\n",
      "   hour=00 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=00 rows=1,382,156 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=07/hour=00/part-000.parquet (6.8s)\n",
      "   hour=01 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=01 rows=1,355,581 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=07/hour=01/part-000.parquet (6.0s)\n",
      "   hour=02 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=02 rows=1,115,726 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=07/hour=02/part-000.parquet (4.6s)\n",
      "   hour=03 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=03 rows=826,710 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=07/hour=03/part-000.parquet (4.0s)\n",
      "   hour=13 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=13 rows=186,935 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=07/hour=13/part-000.parquet (1.9s)\n",
      "   hour=14 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=14 rows=471,817 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=07/hour=14/part-000.parquet (2.8s)\n",
      "   hour=15 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=15 rows=559,343 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=07/hour=15/part-000.parquet (3.0s)\n",
      "   hour=16 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=16 rows=655,936 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=07/hour=16/part-000.parquet (3.9s)\n",
      "   hour=19 files=60 (parallel workers=24)\n",
      "    ...parsed 10/60 files\n",
      "    ...parsed 20/60 files\n",
      "    ...parsed 30/60 files\n",
      "    ...parsed 40/60 files\n",
      "    ...parsed 50/60 files\n",
      "    ...parsed 60/60 files\n",
      "   WROTE hour=19 rows=799,959 -> s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/year=2026/month=02/day=07/hour=19/part-000.parquet (4.2s)\n",
      "\n",
      "DONE  Total hour partitions written: 51\n"
     ]
    }
   ],
   "source": [
    "# FAST MonFri build to S3 Parquet (parallel downloads + safe pagination)\n",
    "# ---------------------------------------------------------------\n",
    "# What it does:\n",
    "# - Builds test dataset for MondayFriday (yesterdays week)\n",
    "# - Discovers available hour=XX partitions automatically per day\n",
    "# - Downloads + parses .pb files in parallel (ThreadPoolExecutor)\n",
    "# - Writes one Parquet per (day, hour) into processed/.../split=test/\n",
    "#\n",
    "# Requirements:\n",
    "#   pip install boto3 pandas pyarrow gtfs-realtime-bindings protobuf\n",
    "#\n",
    "# Notes:\n",
    "# - Uses Feed header timestamp if present; falls back to ts=... from filename.\n",
    "# - S3 \"folders\" don't need to exist beforehand.\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "from datetime import date, timedelta\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from google.transit import gtfs_realtime_pb2\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 0) Date window: MonFri (yesterday)\n",
    "# -------------------------\n",
    "end_date = date.today() - timedelta(days=1)                 # yesterday (Fri)\n",
    "start_date = end_date - timedelta(days=end_date.weekday())  # Monday of same week\n",
    "print(\"Test window:\", start_date, \"\", end_date)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 1) Config\n",
    "# -------------------------\n",
    "bucket = \"bus-delay-forecast\"\n",
    "RAW_BASE = \"gtfs_rt/trip_updates\"\n",
    "OUT_BASE = \"processed/gtfs_rt/trip_updates_parquet/split=test\"\n",
    "\n",
    "# Tune these:\n",
    "MAX_WORKERS = 24          # 1232 is usually good; reduce if you hit throttling\n",
    "MAX_FILES_PER_HOUR = None # set to e.g. 20 for a quick dry run; None = all\n",
    "WRITE_MODE = \"overwrite\"  # \"overwrite\" always writes part-000.parquet (safe reruns)\n",
    "\n",
    "TS_RE = re.compile(r\"ts=(\\d+)\\.pb$\")\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 2) Helpers\n",
    "# -------------------------\n",
    "def list_pb_keys(bucket: str, prefix: str) -> list[str]:\n",
    "    \"\"\"List all .pb keys under prefix (handles pagination).\"\"\"\n",
    "    keys = []\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            k = obj[\"Key\"]\n",
    "            if k.endswith(\".pb\"):\n",
    "                keys.append(k)\n",
    "    keys.sort()\n",
    "    return keys\n",
    "\n",
    "\n",
    "def list_hour_prefixes(bucket: str, day_prefix: str) -> list[str]:\n",
    "    \"\"\"List hour=XX/ prefixes for a given day prefix.\"\"\"\n",
    "    # Delimiter listing returns folders in CommonPrefixes\n",
    "    resp = s3.list_objects_v2(Bucket=bucket, Prefix=day_prefix, Delimiter=\"/\")\n",
    "    return [p[\"Prefix\"] for p in resp.get(\"CommonPrefixes\", [])]\n",
    "\n",
    "\n",
    "def parse_tripupdates(pb_bytes: bytes, default_feed_ts=None) -> list[dict]:\n",
    "    \"\"\"Flatten TripUpdates: 1 row per stop_time_update.\"\"\"\n",
    "    feed = gtfs_realtime_pb2.FeedMessage()\n",
    "    feed.ParseFromString(pb_bytes)\n",
    "\n",
    "    feed_ts = (feed.header.timestamp if feed.header and feed.header.timestamp else default_feed_ts)\n",
    "\n",
    "    rows = []\n",
    "    for ent in feed.entity:\n",
    "        if not ent.HasField(\"trip_update\"):\n",
    "            continue\n",
    "\n",
    "        tu = ent.trip_update\n",
    "        trip = tu.trip\n",
    "\n",
    "        trip_id = trip.trip_id or None\n",
    "        route_id = trip.route_id or None\n",
    "\n",
    "        for stu in tu.stop_time_update:\n",
    "            # delay preference: arrival.delay else departure.delay\n",
    "            delay_sec = None\n",
    "            if stu.HasField(\"arrival\") and stu.arrival.HasField(\"delay\"):\n",
    "                delay_sec = stu.arrival.delay\n",
    "            elif stu.HasField(\"departure\") and stu.departure.HasField(\"delay\"):\n",
    "                delay_sec = stu.departure.delay\n",
    "\n",
    "            rows.append({\n",
    "                \"feed_timestamp\": feed_ts,\n",
    "                \"trip_id\": trip_id,\n",
    "                \"route_id\": route_id,\n",
    "                \"stop_id\": (stu.stop_id or None),\n",
    "                \"stop_sequence\": (stu.stop_sequence if stu.HasField(\"stop_sequence\") else None),\n",
    "                \"delay_sec\": delay_sec,\n",
    "            })\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def fetch_and_parse(key: str) -> list[dict]:\n",
    "    \"\"\"Download one pb object and parse rows.\"\"\"\n",
    "    m = TS_RE.search(key)\n",
    "    ts_from_name = int(m.group(1)) if m else None\n",
    "\n",
    "    pb = s3.get_object(Bucket=bucket, Key=key)[\"Body\"].read()\n",
    "    return parse_tripupdates(pb, default_feed_ts=ts_from_name)\n",
    "\n",
    "\n",
    "def write_parquet_to_s3(df: pd.DataFrame, out_key: str):\n",
    "    \"\"\"Write dataframe as Parquet to S3.\"\"\"\n",
    "    buf = io.BytesIO()\n",
    "    df.to_parquet(buf, index=False)\n",
    "    buf.seek(0)\n",
    "    s3.put_object(Bucket=bucket, Key=out_key, Body=buf.getvalue())\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3) Main loop: MonFri, all hours, fast parallel parse\n",
    "# -------------------------\n",
    "current = start_date\n",
    "total_hours_written = 0\n",
    "\n",
    "while current <= end_date:\n",
    "    y, m, d = current.year, current.month, current.day\n",
    "    day_prefix = f\"{RAW_BASE}/year={y}/month={m:02d}/day={d:02d}/\"\n",
    "\n",
    "    hour_prefixes = list_hour_prefixes(bucket, day_prefix)\n",
    "\n",
    "    print(f\"\\n {current} | hours found: {len(hour_prefixes)} | prefix: {day_prefix}\")\n",
    "\n",
    "    for hour_prefix in hour_prefixes:\n",
    "        # hour_prefix looks like \".../day=DD/hour=14/\"\n",
    "        hour = hour_prefix.split(\"hour=\")[-1].rstrip(\"/\")\n",
    "        t0 = time.time()\n",
    "\n",
    "        keys = list_pb_keys(bucket, hour_prefix)\n",
    "        if not keys:\n",
    "            print(f\"  [SKIP] hour={hour} (no .pb files)\")\n",
    "            continue\n",
    "\n",
    "        if MAX_FILES_PER_HOUR is not None:\n",
    "            keys = keys[:MAX_FILES_PER_HOUR]\n",
    "\n",
    "        print(f\"   hour={hour} files={len(keys)} (parallel workers={MAX_WORKERS})\")\n",
    "\n",
    "        all_rows = []\n",
    "        # Parallel download+parse (I/O bound  threads help a lot)\n",
    "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "            futures = [ex.submit(fetch_and_parse, k) for k in keys]\n",
    "            for i, fut in enumerate(as_completed(futures), 1):\n",
    "                all_rows.extend(fut.result())\n",
    "                if i % 10 == 0 or i == len(keys):\n",
    "                    print(f\"    ...parsed {i}/{len(keys)} files\")\n",
    "\n",
    "        if not all_rows:\n",
    "            print(f\"  [SKIP] hour={hour} (no trip_update rows)\")\n",
    "            continue\n",
    "\n",
    "        df = pd.DataFrame(all_rows)\n",
    "\n",
    "        # Add time features (UTC + Vancouver)\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"feed_timestamp\"], unit=\"s\", utc=True)\n",
    "        df[\"timestamp_pt\"] = df[\"timestamp\"].dt.tz_convert(\"America/Vancouver\")\n",
    "        df[\"hour_pt\"] = df[\"timestamp_pt\"].dt.hour\n",
    "        df[\"day_of_week_pt\"] = df[\"timestamp_pt\"].dt.dayofweek\n",
    "\n",
    "        out_key = f\"{OUT_BASE}/year={y}/month={m:02d}/day={d:02d}/hour={hour}/part-000.parquet\"\n",
    "\n",
    "        write_parquet_to_s3(df, out_key)\n",
    "\n",
    "        total_hours_written += 1\n",
    "        print(\n",
    "            f\"   WROTE hour={hour} rows={len(df):,} -> s3://{bucket}/{out_key} \"\n",
    "            f\"({time.time()-t0:.1f}s)\"\n",
    "        )\n",
    "\n",
    "    current += timedelta(days=1)\n",
    "\n",
    "print(f\"\\nDONE  Total hour partitions written: {total_hours_written}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65bd5187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feed_timestamp</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>delay_sec</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>timestamp_pt</th>\n",
       "      <th>hour_pt</th>\n",
       "      <th>day_of_week_pt</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1770016800</td>\n",
       "      <td>14827965</td>\n",
       "      <td>6612</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>2026-02-02 07:20:00+00:00</td>\n",
       "      <td>2026-02-01 23:20:00-08:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>2026</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1770016800</td>\n",
       "      <td>14827966</td>\n",
       "      <td>6612</td>\n",
       "      <td>1276</td>\n",
       "      <td>9</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2026-02-02 07:20:00+00:00</td>\n",
       "      <td>2026-02-01 23:20:00-08:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>2026</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1770016800</td>\n",
       "      <td>14827966</td>\n",
       "      <td>6612</td>\n",
       "      <td>1277</td>\n",
       "      <td>10</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2026-02-02 07:20:00+00:00</td>\n",
       "      <td>2026-02-01 23:20:00-08:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>2026</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1770016800</td>\n",
       "      <td>14827966</td>\n",
       "      <td>6612</td>\n",
       "      <td>1279</td>\n",
       "      <td>11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2026-02-02 07:20:00+00:00</td>\n",
       "      <td>2026-02-01 23:20:00-08:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>2026</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1770016800</td>\n",
       "      <td>14827966</td>\n",
       "      <td>6612</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2026-02-02 07:20:00+00:00</td>\n",
       "      <td>2026-02-01 23:20:00-08:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>2026</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feed_timestamp   trip_id route_id stop_id  stop_sequence  delay_sec  \\\n",
       "0      1770016800  14827965     6612      31             29      -18.0   \n",
       "1      1770016800  14827966     6612    1276              9       57.0   \n",
       "2      1770016800  14827966     6612    1277             10       49.0   \n",
       "3      1770016800  14827966     6612    1279             11       20.0   \n",
       "4      1770016800  14827966     6612      56             12       10.0   \n",
       "\n",
       "                  timestamp              timestamp_pt  hour_pt  \\\n",
       "0 2026-02-02 07:20:00+00:00 2026-02-01 23:20:00-08:00       23   \n",
       "1 2026-02-02 07:20:00+00:00 2026-02-01 23:20:00-08:00       23   \n",
       "2 2026-02-02 07:20:00+00:00 2026-02-01 23:20:00-08:00       23   \n",
       "3 2026-02-02 07:20:00+00:00 2026-02-01 23:20:00-08:00       23   \n",
       "4 2026-02-02 07:20:00+00:00 2026-02-01 23:20:00-08:00       23   \n",
       "\n",
       "   day_of_week_pt  year month day hour  \n",
       "0               6  2026     2   2    7  \n",
       "1               6  2026     2   2    7  \n",
       "2               6  2026     2   2    7  \n",
       "3               6  2026     2   2    7  \n",
       "4               6  2026     2   2    7  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_parquet(\n",
    "    \"s3://bus-delay-forecast/processed/gtfs_rt/trip_updates_parquet/split=test/\"\n",
    ")\n",
    "\n",
    "df_test.shape\n",
    "df_test.head()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
